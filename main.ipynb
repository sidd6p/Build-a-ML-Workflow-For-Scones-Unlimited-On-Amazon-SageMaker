{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy and monitor a machine learning workflow for Image Classification\n",
    "\n",
    "1. __Data Staging__\n",
    "    1. Extract the data from a hosting service\n",
    "    2. Transform it into a usable shape and format\n",
    "    3. Explore the data\n",
    "    4. Filter the objects to find the label numbers for Bicycle and Motorcycles\n",
    "    5. Convert the object into the dataframe\n",
    "    6. Save the data to the local machine\n",
    "    7. Load it into a production system\n",
    "    \n",
    "2. __Model Training__\n",
    "    1. Create metadata for image classification on SageMaker\n",
    "    2. Upload metadata to S3 using `boto3`\n",
    "    3. Get algorithm using ECR image\n",
    "    4. Create estimator\n",
    "    5. Add hyperparameters to the estimator\n",
    "    6. Add model inputs\n",
    "    7. Fit the model\n",
    "\n",
    "3. __Getting ready to deploy__\n",
    "    1. Creating data capture\n",
    "    2. Model deployment and creating the endpoint\n",
    "    3. Instantiating a predictor\n",
    "    4. Making Prediction\n",
    "    \n",
    "4. __Draft Lambdas and Step Function Workflow__\n",
    "    1. Lambad 1: Serialize target data from S3\n",
    "    2. Lambad 2: Classification of image\n",
    "    3. Lambda 3: Check for confidence threshold\n",
    "    \n",
    "5. __Testing and Evaluation__\n",
    "    1. Generating multiple test cases (event input for lambda 1)\n",
    "    2. Pulling in the JSONLines data from your inferences\n",
    "    3. Plotting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Data Staging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A. Extract the data from the hosting service__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the cell below, define a function `extract_cifar_data` that extracts python version of the CIFAR-100 dataset. \n",
    "- The CIFAR dataaset is open source and generously hosted by the University of Toronto at: https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz \n",
    "- This will download a zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n",
    "file_name = \"cifar.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def extract_cifar_data(url, file_name=\"cifar.tar.gz\"):\n",
    "    \"\"\"\n",
    "    Downloads the CIFAR-100 dataset from the specified URL and saves it as a gzipped file.\n",
    "\n",
    "    This function checks if the CIFAR-100 dataset file already exists in the local directory. \n",
    "    If it doesn't exist, the function downloads the dataset from the provided URL and saves \n",
    "    it locally with the given file name. The file is saved in binary format.\n",
    "\n",
    "    Parameters:\n",
    "    url (str): The URL from which the CIFAR-100 dataset will be downloaded.\n",
    "    file_name (str): The name of the file where the downloaded dataset will be saved.\n",
    "                     Defaults to \"cifar.tar.gz\" if not provided.\n",
    "\n",
    "    Returns:\n",
    "    None: This function does not return any value.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the file already exists in the local directory to avoid redundant downloads\n",
    "    if not os.path.exists(file_name):\n",
    "        # Send a GET request to the specified URL to retrieve the dataset\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Open the file in binary write mode to write the downloaded content\n",
    "        with open(file_name, \"wb\") as file:\n",
    "            # Write the content of the response (the dataset) to the file\n",
    "            file.write(response.content)\n",
    "\n",
    "        # No return value is necessary as the function is intended to save the file only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_cifar_data(download_url, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B. Transform the data into a usable shape and format__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The zip file has 3 compressed form of python serialized object (serialized dict using pickle).\n",
    "- So we will extract the zip and then unpickle them into python dict.\n",
    "- Create a new folder `cifar-100-python`, containing `meta`, `test`, and `train` files, these are serialized python object. \n",
    "- These files are `pickles` and the [CIFAR homepage](https://www.cs.toronto.edu/~kriz/cifar.html) provides a simple script that can be used to load them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "\n",
    "def unzip_data(file_name, mode=\"r:gz\"):\n",
    "    \"\"\"\n",
    "    Unzips a tar.gz file and extracts its contents.\n",
    "\n",
    "    This function checks if a specific directory (cifar-100-python) already exists.\n",
    "    If it does not, the function will extract all contents from the specified tar.gz file.\n",
    "\n",
    "    Parameters:\n",
    "    file_name (str): The name of the tar.gz file to be unzipped.\n",
    "    mode (str, optional): The mode for opening the tar file. Defaults to \"r:gz\", which is read mode for gzipped tar files.\n",
    "\n",
    "    Returns:\n",
    "    None: This function does not return any value. It extracts files to the local directory.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the target directory 'cifar-100-python' already exists\n",
    "    if not os.path.exists(\"cifar-100-python\"):\n",
    "        # Open the gzipped tar file in read mode\n",
    "        with tarfile.open(file_name, mode) as tar:\n",
    "            # Extract all the contents of the tar file to the current directory\n",
    "            tar.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def de_serialize_pickle_data():\n",
    "    \"\"\"\n",
    "    Deserialize CIFAR-100 dataset from pickle files.\n",
    "\n",
    "    This function loads metadata, test data, and training data from pickle files\n",
    "    for the CIFAR-100 dataset. It assumes that these files are stored in a directory\n",
    "    named 'cifar-100-python' and uses the 'bytes' encoding for pickle loading.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing three elements in the following order:\n",
    "               - dataset_meta: The metadata for the dataset.\n",
    "               - dataset_test: The test data of the dataset.\n",
    "               - dataset_train: The training data of the dataset.\n",
    "    \"\"\"\n",
    "    # Load the metadata file\n",
    "    with open(\"./cifar-100-python/meta\", \"rb\") as f:\n",
    "        # Deserialize metadata using pickle with 'bytes' encoding\n",
    "        dataset_meta = pickle.load(f, encoding='bytes')\n",
    "\n",
    "    # Load the test data file\n",
    "    with open(\"./cifar-100-python/test\", \"rb\") as f:\n",
    "        # Deserialize test data using pickle with 'bytes' encoding\n",
    "        dataset_test = pickle.load(f, encoding='bytes')\n",
    "\n",
    "    # Load the training data file\n",
    "    with open(\"./cifar-100-python/train\", \"rb\") as f:\n",
    "        # Deserialize training data using pickle with 'bytes' encoding\n",
    "        dataset_train = pickle.load(f, encoding='bytes')\n",
    "    \n",
    "    return dataset_meta, dataset_test, dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip_data(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_meta, dataset_test, dataset_train = de_serialize_pickle_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C. Explore the data__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All unpicked objects are Python dictionaries.\n",
    "- The train dictionary has 5 keys:\n",
    "    1. `b'filenames'`\n",
    "    2. `b'batch_label'`\n",
    "    3. `b'fine_labels'`\n",
    "    4. `b'coarse_labels'`\n",
    "    5. `b'data'`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- The test dictionary has 5 keys:\n",
    "    1. `b'filenames'`\n",
    "    2. `b'batch_label'`\n",
    "    3. `b'fine_labels'`\n",
    "    4. `b'coarse_labels'`\n",
    "    5. `b'data'`\n",
    "    \n",
    " \n",
    " \n",
    " - The meta dictionary has 2 keys:\n",
    "    1. `b'fine_label_names'`\n",
    "    2. `b'coarse_label_names'`\n",
    "    3. `b'fine_labels'`\n",
    "    4. `b'coarse_labels'`\n",
    "    5. `b'data'`\n",
    "    \n",
    "    \n",
    "    \n",
    "- As documented on the homepage, `b'data'` 50000 contains rows of 3073 unsigned integers, representing three channels (red, green, and blue) for one 32x32 pixel image per row. So total = 32x32x3 = 3072 per index.\n",
    "\n",
    "\n",
    "- `dataset_train[b'fine_labels']` contains the label for the image, this label act as index in `dataset_meta[b'fine_label_names']`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_data():\n",
    "    \"\"\"\n",
    "    Analyzes and prints the types and keys of training, testing datasets and metadata.\n",
    "\n",
    "    This function is designed to work with a specific dataset format where the datasets\n",
    "    and metadata are expected to be in a dictionary-like structure with specific keys.\n",
    "    It prints out the types of various components of the datasets and metadata to\n",
    "    help understand the structure and format of the data.\n",
    "    \"\"\"\n",
    "    # Print the types of the main dataset, filenames, and fine labels in the training set\n",
    "    print(type(dataset_train), type(dataset_train[b'filenames']), type(dataset_train[b'fine_labels']))\n",
    "\n",
    "    # Print the types of metadata, test set, and training set\n",
    "    print(type(dataset_meta), type(dataset_test), type(dataset_train))\n",
    "\n",
    "    # Print the keys of training set, test set, and metadata for understanding their structure\n",
    "    print(dataset_train.keys(), dataset_test.keys(), dataset_meta.keys())\n",
    "\n",
    "    # Print the actual data in the training set, the length of the data array, and the length of the first element in the data array\n",
    "    print(dataset_train[b'data'], len(dataset_train[b'data']), len(dataset_train[b'data'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transform one of our images. \n",
    "Using python, we can stack these channels into a 32x32x3 array, and save it as a PNG file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_single_image(image_array):\n",
    "    \"\"\"\n",
    "    Plot a single image from a flattened array.\n",
    "\n",
    "    This function takes a flattened array representing an image and\n",
    "    reconstructs it into a 32x32 RGB image. The input array is expected\n",
    "    to have the first third of its elements representing the red channel,\n",
    "    the second third the green channel, and the last third the blue channel.\n",
    "\n",
    "    Parameters:\n",
    "    image_array (numpy.ndarray): A flattened array of shape (3072,).\n",
    "                                 It should contain 1024 elements (32x32) for each color channel.\n",
    "\n",
    "    Returns:\n",
    "    None: The function directly plots the image using matplotlib.\n",
    "    \"\"\"\n",
    "    channel_size = 32 * 32  # Size of one color channel\n",
    "\n",
    "    # Split the flattened array into red, green, and blue components\n",
    "    red = image_array[0:channel_size]\n",
    "    green = image_array[channel_size:2 * channel_size]\n",
    "    blue = image_array[2 * channel_size:3 * channel_size]\n",
    "\n",
    "    # Reshape each channel to a 32x32 grid\n",
    "    red = red.reshape(32, 32)\n",
    "    green = green.reshape(32, 32)\n",
    "    blue = blue.reshape(32, 32)\n",
    "\n",
    "    # Stack the channels along the third dimension to form a 32x32x3 RGB image\n",
    "    combined = np.dstack((red, green, blue))\n",
    "\n",
    "    # Display the image using matplotlib\n",
    "    plt.imshow(combined)\n",
    "    plt.show()  # This line ensures that the plot is displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_labels():\n",
    "    \"\"\"\n",
    "    This function prints the first five labels and their corresponding names from the training dataset.\n",
    "    It also prints the name of the label and the filename associated with the first data entry in the dataset.\n",
    "\n",
    "    The function assumes the existence of a training dataset `dataset_train` and a metadata set `dataset_meta`,\n",
    "    both of which are expected to be dictionaries with byte string keys.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Print the first five labels and their corresponding names from the training dataset\n",
    "    print(dataset_train[b'fine_labels'][0:5], dataset_meta[b'fine_label_names'][0:5])\n",
    "    \n",
    "    # Print the label name for the first label in the training dataset\n",
    "    print(dataset_meta[b'fine_label_names'][dataset_train[b'fine_labels'][0]])\n",
    "    \n",
    "    # Print the filename associated with the first data entry in the dataset\n",
    "    print(dataset_train[b'filenames'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_single_image(dataset_train[b'data'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looks like a cow! Let's check the label. `dataset_meta` contains label names in order, and `dataset_train` has a list of labels for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Index in `dataset_meta[b'fine_label_names']` are actually the labels.\n",
    "- \"Taurus\" is the name of a subspecies of cattle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__D. Filter the objects to find the label numbers for Bicycle and Motorcycles__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CIFAR-100 has image for 100 classes, we need to filter the label that are accosicated with bicycle and motorcycle class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_label():\n",
    "    \"\"\"\n",
    "    Searches through a dataset's metadata to find specific labels.\n",
    "\n",
    "    This function iterates over the 'fine_label_names' in 'dataset_meta' and\n",
    "    prints out the name and index of labels that are either 'bicycle' or 'motorcycle'.\n",
    "\n",
    "    Args:\n",
    "    None: The function assumes 'dataset_meta' is a globally accessible variable \n",
    "          containing the dataset metadata.\n",
    "\n",
    "    Returns:\n",
    "    None: This function prints the label names and their corresponding indices, \n",
    "          but does not return any value.\n",
    "    \"\"\"\n",
    "    # Iterate over each label in the dataset's metadata\n",
    "    for index, label_name in enumerate(dataset_meta[b'fine_label_names']):\n",
    "        # Check if the current label is either 'bicycle' or 'motorcycle'\n",
    "        if label_name in [b'bicycle', b'motorcycle']:\n",
    "            # Print the label name and its index\n",
    "            print(f\"Label Name: {label_name}, Label Number: {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_label()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__E. Convert the object into the dataframe__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_to_df(dataset_train, dataset_test):\n",
    "    \"\"\"\n",
    "    Convert training and testing datasets into pandas DataFrames.\n",
    "\n",
    "    This function takes two datasets (training and testing) and converts them into pandas DataFrames. \n",
    "    It filters the datasets to include only rows where the label is either 8 or 48. \n",
    "    Additionally, it decodes the filenames from bytes to strings.\n",
    "\n",
    "    Parameters:\n",
    "    dataset_train (dict): A dictionary containing the training dataset with keys for 'filenames' and 'fine_labels'.\n",
    "    dataset_test (dict): A dictionary containing the testing dataset with keys for 'filenames' and 'fine_labels'.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two pandas DataFrames, one for the training data and the other for the testing data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Construct the dataframe for training data\n",
    "    df_train = pd.DataFrame({\n",
    "        \"filenames\": dataset_train[b'filenames'],\n",
    "        \"labels\": dataset_train[b'fine_labels'],\n",
    "        \"row\": range(len(dataset_train[b'filenames']))  # Adding an index column\n",
    "    })\n",
    "\n",
    "    # Filter df_train to include only rows with labels 8 or 48\n",
    "    df_train = df_train.loc[df_train[\"labels\"].isin([8, 48])]\n",
    "\n",
    "    # Decode filenames in df_train from bytes to regular strings\n",
    "    df_train[\"filenames\"] = df_train[\"filenames\"].apply(lambda x: x.decode(\"utf-8\"))\n",
    "\n",
    "    # Construct the dataframe for testing data\n",
    "    df_test = pd.DataFrame({\n",
    "        \"filenames\": dataset_test[b'filenames'],\n",
    "        \"labels\": dataset_test[b'fine_labels'],\n",
    "        \"row\": range(len(dataset_test[b'filenames']))  # Adding an index column\n",
    "    })\n",
    "\n",
    "    # Filter df_test to include only rows with labels 8 or 48\n",
    "    df_test = df_test.loc[df_test[\"labels\"].isin([8, 48])]\n",
    "\n",
    "    # Decode filenames in df_test from bytes to regular strings\n",
    "    df_test[\"filenames\"] = df_test[\"filenames\"].apply(lambda x: x.decode(\"utf-8\"))\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_df(df_train, df_test):\n",
    "    \"\"\"\n",
    "    Perform and display basic analysis on two pandas DataFrames.\n",
    "\n",
    "    This function prints the first few rows (head) and a descriptive\n",
    "    statistical summary of two DataFrames, typically used for training\n",
    "    and testing in machine learning contexts.\n",
    "\n",
    "    Parameters:\n",
    "    df_train (DataFrame): The training dataset as a pandas DataFrame.\n",
    "    df_test (DataFrame): The testing dataset as a pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    None: This function does not return anything. It only prints DataFrame information.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Print the first few rows of the training dataset to get an overview\n",
    "    print(df_train.head())\n",
    "    \n",
    "    # Print descriptive statistics for the training dataset\n",
    "    print(df_train.describe())\n",
    "    \n",
    "    # Print the first few rows of the testing dataset to get an overview\n",
    "    print(df_test.head())\n",
    "    \n",
    "    # Print descriptive statistics for the testing dataset\n",
    "    print(df_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = convert_to_df(dataset_train, dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `df_train` and `df_test` have filename, lable, and index from original data dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__F. Save the data to the local machine__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./train # Create a 'train' directory in the current working directory\n",
    "!mkdir ./test # Create a 'test' directory in the current working director"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Grabbing the image data:\n",
    "\n",
    "```python\n",
    "dataset_train[b'data'][0]\n",
    "```\n",
    "\n",
    "2. A simple idiom for stacking the image data into the right shape\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "np.dstack((\n",
    "    row[0:1024].reshape(32,32),\n",
    "    row[1024:2048].reshape(32,32),\n",
    "    row[2048:].reshape(32,32)\n",
    "))\n",
    "```\n",
    "\n",
    "3. A simple `matplotlib` utility for saving images\n",
    "\n",
    "```python\n",
    "plt.imsave(path+row['filenames'], target)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(image_data_row_num, image_filename, target_folder_path, images_dataset):\n",
    "    \"\"\"\n",
    "    Saves an image from a dataset to a specified folder.\n",
    "\n",
    "    This function retrieves image data from a specified row in an image dataset and saves it\n",
    "    to the target folder with the given filename. The image data is assumed to be in a specific\n",
    "    format and is reshaped and stacked to form the final image.\n",
    "\n",
    "    Arguments:\n",
    "    image_data_row_num : int\n",
    "        The row number in the dataset from which to retrieve image data.\n",
    "    image_filename : str\n",
    "        The filename under which the image will be saved.\n",
    "    target_folder_path : str\n",
    "        The path to the folder where the image will be saved.\n",
    "    images_dataset : array-like\n",
    "        The dataset containing the image data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve the image data from the specified row in the dataset.\n",
    "    img_data = images_dataset[b'data'][image_data_row_num]\n",
    "\n",
    "    # Process the image data: Reshape and stack it to form a three-channel image.\n",
    "    # Assumes the image data is in row-major form and needs to be divided into three equal parts,\n",
    "    # each corresponding to one color channel (e.g., RGB).\n",
    "    target = np.dstack((\n",
    "        img_data[0:1024].reshape(32, 32),  # Red channel\n",
    "        img_data[1024:2048].reshape(32, 32),  # Green channel\n",
    "        img_data[2048:].reshape(32, 32)  # Blue channel\n",
    "    ))\n",
    "\n",
    "    # Try to save the processed image to the specified path.\n",
    "    try:\n",
    "        # Construct the full path where the image will be saved.\n",
    "        image_file_path = os.path.join(target_folder_path, image_filename)\n",
    "        # Save the image using the matplotlib's imsave function.\n",
    "        plt.imsave(image_file_path, target)\n",
    "    except Exception as e:\n",
    "        # If an error occurs, return an error message.\n",
    "        return f\"Error Saving {image_filename} to folder {target_folder_path} \\n Error: {e}\"\n",
    "\n",
    "    # If the image is saved successfully, return a success message.\n",
    "    return f\"Successfully saved {image_filename} to folder {target_folder_path}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Looping through each row of the train dataframe using itertuples for efficiency\n",
    "for df_row in df_train.itertuples():\n",
    "    # Calling the save_images function for each row in the train dataframe\n",
    "    # Passing the current row's index, filenames, a path to save the images, and the train dataset\n",
    "    # The save_images function is assumed to save images based on the provided parameters\n",
    "    print(save_images(df_row.row, df_row.filenames, \"./train\", dataset_train))\n",
    "\n",
    "# Similar process is repeated for the test dataframe\n",
    "# Looping through each row of the test dataframe\n",
    "for df_row in df_test.itertuples():\n",
    "    # Calling the save_images function for each row in the test dataframe\n",
    "    # Parameters are similar to the above but with the test dataset and path\n",
    "    print(save_images(df_row.row, df_row.filenames, \"./test\", dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__G. Load the data__\n",
    "\n",
    "- Now we can load the data into S3.\n",
    "- Using the sagemaker SDK grab the current region, execution role, and bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the SageMaker module from the AWS SDK\n",
    "import sagemaker\n",
    "\n",
    "# Setting the name of the S3 bucket to be used\n",
    "bucket = \"sidd0final0project0bucket\"\n",
    "# Printing the name of the default bucket\n",
    "print(\"Default Bucket: {}\".format(bucket))\n",
    "\n",
    "# Setting the AWS region where the operations will be performed\n",
    "region = \"us-east-1\"\n",
    "# Printing the AWS region being used\n",
    "print(\"AWS Region: {}\".format(region))\n",
    "\n",
    "# Defining the role ARN (Amazon Resource Name) for SageMaker execution\n",
    "role = \"arn:aws:iam::271232843618:role/service-role/AmazonSageMaker-ExecutionRole-20231021T211247\"\n",
    "# Printing the role ARN\n",
    "print(\"RoleArn: {}\".format(role))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this data we can easily sync your data up into S3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_to_s3(bucket):\n",
    "    \"\"\"\n",
    "    Saves local 'train' and 'test' directories to an S3 bucket.\n",
    "\n",
    "    This function sets the environment variable 'DEFAULT_S3_BUCKET' to the specified bucket name. \n",
    "    It then synchronizes the contents of the local 'train' and 'test' directories with the corresponding \n",
    "    directories in the specified S3 bucket.\n",
    "\n",
    "    Parameters:\n",
    "    bucket (str): The name of the S3 bucket where the data will be saved.\n",
    "\n",
    "    Note: This function relies on the AWS CLI being installed and properly configured on the system.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the environment variable for the default S3 bucket\n",
    "    os.environ[\"DEFAULT_S3_BUCKET\"] = bucket\n",
    "\n",
    "    # Sync the local 'train' directory with the 'train' directory in the specified S3 bucket\n",
    "    !aws s3 sync ./train s3://${DEFAULT_S3_BUCKET}/train/\n",
    "\n",
    "    # Sync the local 'test' directory with the 'test' directory in the specified S3 bucket\n",
    "    !aws s3 sync ./test s3://${DEFAULT_S3_BUCKET}/test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_s3(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Image Classification, Sagemaker [also expects metadata](https://docs.aws.amazon.com/sagemaker/latest/dg/image-classification.html) e.g. in the form of TSV files with labels and filepaths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A. Creating metadata for image classification on SageMaker__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_metadata_file(df, prefix):\n",
    "    \"\"\"\n",
    "    Convert a DataFrame to a metadata file with specific columns.\n",
    "\n",
    "    This function takes a DataFrame and a prefix string as input. It modifies the DataFrame \n",
    "    by creating an 's3_path' column from 'filenames' column and modifies the 'labels' column. \n",
    "    It then saves a subset of this DataFrame to a tab-separated file with the specified prefix.\n",
    "\n",
    "    Args:\n",
    "    df (DataFrame): The DataFrame to be processed. It should contain 'filenames' and 'labels' columns.\n",
    "    prefix (str): A string prefix for the output file name.\n",
    "\n",
    "    Returns:\n",
    "    None: The function writes to a file and does not return anything.\n",
    "    \"\"\"\n",
    "\n",
    "    # Copy filenames to a new column 's3_path'\n",
    "    df[\"s3_path\"] = df[\"filenames\"]\n",
    "\n",
    "    # Convert labels, setting 0 where original label is 8, else 1\n",
    "    df[\"labels\"] = df[\"labels\"].apply(lambda x: 0 if x == 8 else 1)\n",
    "\n",
    "    # Selecting specific columns and saving them to a tab-separated file\n",
    "    return df[[\"row\", \"labels\", \"s3_path\"]].to_csv(\n",
    "        f\"{prefix}.lst\", sep=\"\\t\", index=False, header=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_metadata_file(df_train.copy(), \"train\")\n",
    "to_metadata_file(df_test.copy(), \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B. Uploading metadata to S3 using boto3__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3  # Importing the boto3 library to interact with AWS services.\n",
    "\n",
    "def save_meta_to_s3(bucket):\n",
    "    \"\"\"\n",
    "    Uploads 'train.lst' and 'test.lst' files to an AWS S3 bucket.\n",
    "\n",
    "    This function creates a new session with AWS and uses the boto3 library\n",
    "    to interact with the specified S3 bucket. It uploads two files, 'train.lst'\n",
    "    and 'test.lst', from the local directory to the S3 bucket.\n",
    "\n",
    "    Args:\n",
    "    bucket (str): The name of the S3 bucket where the files will be uploaded.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Creating a new session with AWS.\n",
    "    aws_session = boto3.Session()\n",
    "\n",
    "    # Uploading 'train.lst' to the specified S3 bucket.\n",
    "    aws_session.resource('s3').Bucket(bucket).Object('train.lst').upload_file('./train.lst')\n",
    "\n",
    "    # Uploading 'test.lst' to the specified S3 bucket.\n",
    "    aws_session.resource('s3').Bucket(bucket).Object('test.lst').upload_file('./test.lst')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_meta_to_s3(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C. Getting algorithm using ECR image__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the `bucket` and `region` info we can get the latest prebuilt container to run our training job, and define an output location on our s3 bucket for the model. \n",
    "- Use the `image_uris` function from the SageMaker SDK to retrieve the latest `image-classification` image below\n",
    "- The retrieve method is used to get the ECR (Elastic Container Registry) URI for a pre-built SageMaker Docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(region):\n",
    "    \"\"\"\n",
    "    Retrieves the latest Amazon SageMaker image URI for image classification in a specified region.\n",
    "\n",
    "    This function uses the Amazon SageMaker API to retrieve the URI (Uniform Resource Identifier)\n",
    "    of the latest image classification model available in the specified AWS region. This URI can be used\n",
    "    to deploy the image classification model in that region.\n",
    "\n",
    "    Args:\n",
    "    region (str): The AWS region for which the image classification URI is requested.\n",
    "\n",
    "    Returns:\n",
    "    str: The URI of the latest image classification model for the specified region.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve and return the latest image URI for image classification in the specified region\n",
    "    return sagemaker.image_uris.retrieve(\"image-classification\", region=region, version=\"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_image =get_image(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__D. Creating estimator__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s3_output_location(bucket):\n",
    "    \"\"\"\n",
    "    Construct and return the S3 output location for storing models.\n",
    "\n",
    "    This function takes an S3 bucket name as input and returns a string\n",
    "    that represents the path in the S3 bucket where image models are stored.\n",
    "\n",
    "    Parameters:\n",
    "    bucket (str): The name of the S3 bucket.\n",
    "\n",
    "    Returns:\n",
    "    str: The full S3 path for storing image models.\n",
    "    \"\"\"\n",
    "    # Format and return the S3 path specific for models, particularly image models\n",
    "    return f\"s3://{bucket}/models/image_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimator(algo_image, role, s3_output_location):\n",
    "    \"\"\"\n",
    "    Create and return a SageMaker Estimator.\n",
    "\n",
    "    This function initializes a SageMaker Estimator with specified parameters. \n",
    "    The Estimator is used for training machine learning models in AWS SageMaker.\n",
    "\n",
    "    Parameters:\n",
    "    algo_image (str): The URI of the algorithm image to be used for training.\n",
    "    role (str): The AWS IAM role with required permissions for SageMaker operations.\n",
    "    s3_output_location (str): The S3 location for saving the output of model training.\n",
    "\n",
    "    Returns:\n",
    "    sagemaker.estimator.Estimator: An Estimator object initialized with the specified settings.\n",
    "\n",
    "    Example:\n",
    "    >>> estimator = get_estimator(\"image-uri\", \"sagemaker-role\", \"s3://output-location\")\n",
    "    >>> print(type(estimator))\n",
    "    <class 'sagemaker.estimator.Estimator'>\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a SageMaker Estimator with the specified parameters\n",
    "    return sagemaker.estimator.Estimator(\n",
    "        image_uri=algo_image,             # URI of the algorithm image\n",
    "        role=role,                        # AWS IAM role\n",
    "        instance_count=1,                 # Number of instances to use for training\n",
    "        instance_type='ml.p3.2xlarge',    # Type of instance to use for training\n",
    "        output_path=s3_output_location,   # S3 path to store the output\n",
    "        sagemaker_session=sagemaker.Session()  # Create a SageMaker session\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = get_s3_output_location()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_classifier_model=get_estimator(algo_image, role, s3_output_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__E. Adding hyperparameters to the estimator__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting hyperparameters for the image classification model.\n",
    "img_classifier_model.set_hyperparameters(\n",
    "    image_shape='3,32,32',  # Defines the shape of input images: 3 channels (RGB) and 32x32 pixels in size.\n",
    "    num_classes=2,  # Specifies the number of classes for classification. In this case, there are 2 classes.\n",
    "    num_training_samples=df_train.shape[0]  # Sets the number of training samples using the size of the training dataset.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__F. Adding model inputs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules from the sagemaker package.\n",
    "from sagemaker.debugger import Rule, rule_configs\n",
    "from sagemaker.session import TrainingInput\n",
    "\n",
    "# Defining the inputs for the model training process.\n",
    "model_inputs = {\n",
    "    # Setting up the training input. \n",
    "    # This specifies where the training data is stored (in an S3 bucket) and its content type.\n",
    "    \"train\": sagemaker.inputs.TrainingInput(\n",
    "        s3_data=f\"s3://{bucket}/train/\",  # Path to training data in the S3 bucket.\n",
    "        content_type=\"application/x-image\"  # The type of content, in this case, images.\n",
    "    ),\n",
    "    # Setting up the validation input.\n",
    "    # This is similar to the training input but points to the validation dataset.\n",
    "    \"validation\": sagemaker.inputs.TrainingInput(\n",
    "        s3_data=f\"s3://{bucket}/test/\",  # Path to validation data in the S3 bucket.\n",
    "        content_type=\"application/x-image\"  # Content type for validation data.\n",
    "    ),\n",
    "    # Setting up the training list input.\n",
    "    # This is typically a file that lists the training images and their labels.\n",
    "    \"train_lst\": sagemaker.inputs.TrainingInput(\n",
    "        s3_data=f\"s3://{bucket}/train.lst\",  # Path to the training list file.\n",
    "        content_type=\"application/x-image\"  # Content type for the list file.\n",
    "    ),\n",
    "    # Setting up the validation list input.\n",
    "    # This is similar to the training list but for validation data.\n",
    "    \"validation_lst\": sagemaker.inputs.TrainingInput(\n",
    "        s3_data=f\"s3://{bucket}/test.lst\",  # Path to the validation list file.\n",
    "        content_type=\"application/x-image\"  # Content type for the validation list file.\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__G. Fitting the model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_classifier_model.fit(inputs=model_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If all goes well, you'll end up with a model topping out above `.8` validation accuracy. With only 1000 training samples in the CIFAR dataset, that's pretty good.\n",
    "- We could definitely pursue data augmentation & gathering more samples to help us improve further, but for now let's proceed to deploy our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Getting ready to deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A. Creating data capture__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DataCaptureConfig from the sagemaker.model_monitor module.\n",
    "# This is used to configure the capturing of data for SageMaker model endpoints.\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "\n",
    "# Define the data capture configuration for a SageMaker model endpoint.\n",
    "data_capture_config = DataCaptureConfig(\n",
    "    enable_capture=True, # Enable capturing of input/output payloads for the endpoint.\n",
    "    sampling_percentage=100, # Set to capture data from every request (100% sampling).\n",
    "    destination_s3_uri=f\"s3://{bucket}/data_capture\" # Specify the S3 bucket URI where the captured data will be stored.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B. Model deployment and creating the endpoint__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploying an image classification model using a deployment configuration.\n",
    "\n",
    "# The 'deploy' method is used to deploy the trained model for serving predictions.\n",
    "deployment = img_classifier_model.deploy(\n",
    "    # 'instance_type' specifies the type of machine on which to deploy the model.\n",
    "    # Here, \"ml.m5.xlarge\" is selected, which is a specific type of instance provided by the service.\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "\n",
    "    # 'initial_instance_count' indicates the number of instances to start for the deployment.\n",
    "    # Here, it is set to 1, meaning the model will be deployed on a single instance.\n",
    "    initial_instance_count=1,\n",
    "\n",
    "    # 'data_capture_config' is the configuration for capturing input/output data from the model's predictions.\n",
    "    # This is used for monitoring the model's performance and the data it is processing.\n",
    "    data_capture_config=data_capture_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint = deployment.endpoint_name\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C. Instantiating a predictor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the SageMaker module from the AWS SDK\n",
    "import sagemaker\n",
    "\n",
    "# Creating an instance of the Predictor class from the SageMaker module.\n",
    "predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name=endpoint, # Specifying the name of the endpoint to send requests to.\n",
    "    sagemaker_session=sagemaker.Session() # Creating a new SageMaker session.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__D. Making Prediction__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the IdentitySerializer class from SageMaker's serializers module.\n",
    "from sagemaker.serializers import IdentitySerializer\n",
    "\n",
    "# Import the base64 module for encoding operations.\n",
    "import base64\n",
    "\n",
    "# Set the serializer for the predictor. Here, IdentitySerializer is used to\n",
    "# send the payload as-is without any transformation. The content type is set to 'image/png',\n",
    "# indicating that the input will be an image in PNG format.\n",
    "predictor.serializer = IdentitySerializer(\"image/png\")\n",
    "\n",
    "# Open an image file in read-binary mode. The image is located at \"./test/bicycle_s_001789.png\".\n",
    "with open(\"./test/bicycle_s_001789.png\", \"rb\") as f:\n",
    "    # Read the contents of the file (the image data) into a variable named 'payload'.\n",
    "    payload = f.read()\n",
    "\n",
    "# Make a prediction using the predictor. The 'predict' method is called with the image data (payload).\n",
    "# The 'initial_args' parameter specifies the content type of the input data as 'application/x-image',\n",
    "# which is a general content type for images.\n",
    "inference = predictor.predict(payload, initial_args={'ContentType': 'application/x-image'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `inference` object is an array of two values, the predicted probability value for each of your classes (bicycle and motorcycle respectively.) \n",
    "- So, for example, a value of `b'[0.91, 0.09]'` indicates the probability of being a bike is 91% and being a motorcycle is 9%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Draft Lambdas and Step Function Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A. Lambad 1: Serialize target data from S3__\n",
    "\n",
    "- Download an image file from an S3 bucket\n",
    "- Convert the image data into a base64-encoded format\n",
    "- Return this data along with some metadata as a response\n",
    "\n",
    "- event input\n",
    "```\n",
    "{\n",
    "    \"s3_key\": \"test/bicycle_s_000030.png\",\n",
    "    \"s3_bucket\": \"ml-flow-sidd\"\n",
    "}\n",
    "```\n",
    "\n",
    "- The lambda_handler function is defined, which is the entry point for the Lambda function. \n",
    "- This function takes two parameters: event and context. \n",
    "- The event parameter contains information about the event that triggered the Lambda function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import base64  # For encoding and decoding data in base64 format\n",
    "\n",
    "# Initialize an S3 client using boto3\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"\n",
    "    Handles an AWS Lambda event by retrieving an image from an S3 bucket, \n",
    "    encoding it in base64 format, and returning the encoded data along with S3 metadata.\n",
    "\n",
    "    Args:\n",
    "    event (dict): A dictionary containing 's3_key' and 's3_bucket', \n",
    "                  which are the key and bucket name of the S3 object to process.\n",
    "    context (LambdaContext): Provides runtime information to the handler.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing the status code, base64 encoded image data, \n",
    "          and the S3 bucket and key information.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the S3 key and bucket information from the event\n",
    "    key = event[\"s3_key\"]\n",
    "    bucket = event[\"s3_bucket\"]\n",
    "    \n",
    "    # Download the data from S3 to a temporary location on the Lambda environment\n",
    "    boto3.resource('s3').Bucket(bucket).download_file(key, \"/tmp/image.png\")\n",
    "    \n",
    "    # Open the downloaded image file for reading in binary mode\n",
    "    with open(\"/tmp/image.png\", \"rb\") as f:\n",
    "        # Read the file and encode its content in base64\n",
    "        image_data = base64.b64encode(f.read())\n",
    "\n",
    "    # Return a dictionary containing the status code, base64 encoded image data, and S3 object information\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': {\n",
    "            \"image_data\": image_data,\n",
    "            \"s3_bucket\": bucket,\n",
    "            \"s3_key\": key,\n",
    "            \"inferences\": []  # Placeholder for any additional processing results\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B. Lambad 2: Classification of image__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creates a SageMaker runtime client using boto3.client('runtime.sagemaker') to interact with the SageMaker endpoint.\n",
    "- Send an image (in base64-encoded format) to an Amazon SageMaker endpoint for inference \n",
    "- Return the inference results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import base64\n",
    "\n",
    "# The name of the endpoint in AWS SageMaker to be invoked\n",
    "ENDPOINT_NAME = endpoint\n",
    "\n",
    "# Create a SageMaker runtime client using Boto3. This is used to invoke the SageMaker endpoint.\n",
    "runtime = boto3.client('runtime.sagemaker')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"\n",
    "    Handles a Lambda function invocation for image processing.\n",
    "\n",
    "    This function takes an event containing base64-encoded image data,\n",
    "    decodes it, and sends it to a SageMaker endpoint for inference.\n",
    "    It then returns the inference result in the response.\n",
    "\n",
    "    Parameters:\n",
    "    - event (dict): A dictionary containing the input data for the Lambda function. \n",
    "                    Expected to have a 'body' key with 'image_data' as base64-encoded string.\n",
    "    - context: Information about the runtime environment. This is unused in this function.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary with the status code and the body containing the inference result.\n",
    "    \"\"\"\n",
    "\n",
    "    # Decode the base64-encoded image data from the event\n",
    "    image = base64.b64decode(event['body']['image_data'])\n",
    "    \n",
    "    # Invoke the SageMaker endpoint with the decoded image\n",
    "    response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME,\n",
    "                                       ContentType='image/png',\n",
    "                                       Body=image)\n",
    "    \n",
    "    # Decode the response and add it to the event dictionary under the key 'inferences'\n",
    "    event[\"inferences\"] = json.loads(response['Body'].read().decode('utf-8'))\n",
    "\n",
    "    # Return the status code and the modified event as the response\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': event\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C. Lambda 3: Check for confidence threshold__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the threshold for confidence\n",
    "THRESHOLD = 0.8 \n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"\n",
    "    Handler function for AWS Lambda to process inferences.\n",
    "\n",
    "    This function takes an event containing inferences and evaluates if any of the inferences\n",
    "    meet a predefined confidence threshold. If the threshold is met, it returns the event data,\n",
    "    otherwise, it raises an exception.\n",
    "\n",
    "    Parameters:\n",
    "    event (dict): The event data containing 'inferences' key with a list of confidence values.\n",
    "    context: The context in which the Lambda function is running, provided by AWS Lambda.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with statusCode and the original event data in JSON format if the threshold is met.\n",
    "\n",
    "    Raises:\n",
    "    Exception: If none of the inferences meet the required confidence threshold.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract inferences from the event body\n",
    "    inferences =  event['body']['inferences']\n",
    "    \n",
    "    # Check if any values in our inferences are above the THRESHOLD\n",
    "    # Iterates through each confidence score in inferences to check against THRESHOLD\n",
    "    meets_threshold = any(confidence >= THRESHOLD for confidence in inferences)\n",
    "    \n",
    "    # Conditional action based on whether the threshold is met\n",
    "    if meets_threshold:\n",
    "        # Continue if at least one inference meets the threshold\n",
    "        pass\n",
    "    else:\n",
    "        # Raise an exception if threshold is not met\n",
    "        raise Exception(\"THRESHOLD_CONFIDENCE_NOT_MET\")\n",
    "    \n",
    "    # Return the original event as a JSON string with a status code of 200\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps(event)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Testing and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A. Generating multiple test cases (event input for lambda 1)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "def generate_test_case():\n",
    "    \"\"\"\n",
    "    Generate a test case for an image processing system.\n",
    "\n",
    "    This function selects a random object from the 'test/' folder of an S3 bucket\n",
    "    and returns its key along with the bucket name in a JSON format. It's assumed\n",
    "    that the S3 bucket contains test images for the system.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON string containing the S3 bucket name and the key of a randomly\n",
    "             selected object from the 'test/' folder.\n",
    "    \"\"\"\n",
    "    # Initialize a boto3 resource for Amazon S3\n",
    "    s3 = boto3.resource('s3')\n",
    "    \n",
    "    # Filter objects in the specified S3 bucket with a prefix 'test/'\n",
    "    # It assumes 'bucket' is a predefined variable representing the S3 bucket name\n",
    "    objects = s3.Bucket(bucket).objects.filter(Prefix=\"test/\")\n",
    "    \n",
    "    # Choose a random object from the filtered list\n",
    "    # The list comprehension creates a list of object keys from the filtered objects\n",
    "    obj = random.choice([x.key for x in objects])\n",
    "    \n",
    "    # Construct and return a JSON string with the necessary data\n",
    "    # 'image_data' is left empty as a placeholder for any additional data if needed\n",
    "    return json.dumps({\n",
    "        \"image_data\": \"\",\n",
    "        \"s3_bucket\": bucket,\n",
    "        \"s3_key\": obj\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_test_case()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__B. Pulling in the JSONLines data from your inferences__\n",
    "\n",
    "    1. Downloading the capture (in JSONL format)\n",
    "    2. Extracting JSONL format in dict\n",
    "    3. Loading inferences along with timestamp\n",
    "    4. Visulaizing (the input images, the resulting inferences, and the timestamps.)\n",
    "    \n",
    " - The data are in JSONLines format, where multiple valid JSON objects are stacked on top of eachother in a single `jsonl` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the S3Downloader module from the sagemaker.s3 package.\n",
    "# This module provides utilities for downloading data from Amazon S3 storage.\n",
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "# Defining the S3 path where the data is stored.\n",
    "# The data is organized in a datetime-aware format within the specified S3 bucket.\n",
    "# This path points to a specific dataset related to image classification, captured on a specific date and time.\n",
    "data_path = \"s3://sidd0final0project0bucket/data_capture/image-classification-2023-10-25-10-26-31-173/AllTraffic/2023/10/26/14/\"\n",
    "\n",
    "# Using the S3Downloader to download the data from the specified S3 path.\n",
    "# The data is downloaded and saved locally in a directory named 'captured_data'.\n",
    "# This enables further processing or analysis of the downloaded data.\n",
    "S3Downloader.download(data_path, \"captured_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the jsonlines library to work with JSONL files\n",
    "!pip install jsonlines\n",
    "\n",
    "import jsonlines\n",
    "import os\n",
    "\n",
    "# List the file names in the 'captured_data' directory\n",
    "file_handles = os.listdir(\"./captured_data\")\n",
    "\n",
    "# Initialize an empty list to store JSON data\n",
    "json_data = []\n",
    "# Loop through each file in the directory\n",
    "for jsonl in file_handles:\n",
    "    # Open the JSONL file using jsonlines library\n",
    "    with jsonlines.open(f\"./captured_data/{jsonl}\") as f:\n",
    "        # Read the contents of the file and append it to the json_data list\n",
    "        json_data.append(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how we'll get our data\n",
    "def simple_getter(obj):\n",
    "    inferences = obj[\"captureData\"][\"endpointOutput\"][\"data\"]\n",
    "    timestamp = obj[\"eventMetadata\"][\"inferenceTime\"]\n",
    "    return json.loads(inferences), timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C. Plotting the results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Populate the data for the x and y axis\n",
    "x = []\n",
    "y = []\n",
    "for obj in json_data:\n",
    "    inference, timestamp = simple_getter(obj)\n",
    "    \n",
    "    y.append(max(inference))\n",
    "    x.append(timestamp)\n",
    "\n",
    "# Plot the data\n",
    "plt.scatter(x, y, c=['r' if k<. else 'b' for k in y ])\n",
    "plt.axhline(y=0.8, color='g', linestyle='--')\n",
    "plt.ylim(bottom=.6)\n",
    "\n",
    "# Add labels\n",
    "plt.ylabel(\"Confidence\")\n",
    "plt.suptitle(\"Observed Recent Inferences\", size=14)\n",
    "plt.title(\"Pictured with confidence threshold for production use\", size=10)\n",
    "\n",
    "# Give it some pizzaz!\n",
    "plt.style.use(\"Solarize_Light2\")\n",
    "plt.gcf().autofmt_xdate()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(x, y)    \n",
    "plt.xlabel(\"Inference\")\n",
    "plt.ylabel(\"Confidence Level\")\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
